overall:
  agent_name: "ddpg"
  env_name: "LunarLanderContinuous-v2"
  context_capacity: 1000000
  checkpoint:
    save:
      enabled: true
      history: 100
    load:
      enabled: false
      use_latest_run: false
      custom_dir: models/
  output:
    verbose: true
    render: false
    save:
      episodes: 5
      csv: true
      charts: true
      raw: false
      recordings: true
  episodes:
    max: 1000
  timesteps:
    max: 1000000000000000
    start_training: 50
agents:
  random:
    foo: "bar"
  ddpg:
    alpha: 0.000025
    beta: 0.00025
    gamma: 0.99
    tau: 0.001
    batch_size: 64
    layer1_size: 400
    layer2_size: 300
    n_actions: 2
    max_size: 1000000
  sac:
    sample_size: 50
    batch_size: 64
    learning_rate: 0.0001
    alpha: 0.9
    gamma: 0.99
    scale: 2
    tau: 0.05
    nn_initial_weights: 0.0003
    actor_noise: 0.000001
    no_hidden_neurons: 256
  dqn:
    learning_rate: 0.00005
    batch_size: 64
    sample_size: 50
    hidden_layer_size: 64
    update_count: 4
    epsilon: 0.99
    epsilon_decay: 0.0001
    epsilon_min: 0.01
    gamma: 0.99
    tau: 0.0003
  sarsa:
    gamma: 0.99
    tau: 0.01
    sample_size: 64
    batch_size: 128
